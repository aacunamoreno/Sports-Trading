<analysis>**original_problem_statement:** The user wants to build an automated betting analysis system for the website . The system should scrape game data (lines, scores, spreads, moneylines), betting consensus data, calculate betting edges, track user bets, and display all information in a unified dashboard.

The project has evolved into a hands-on, user-guided process of backfilling historical data for multiple sports leagues (NFL, NBA, NHL, NCAAB), correcting discrepancies, and adding new UI features to analyze this data.

**User's preferred language**: English

**what currently exists?**
A full-stack application with a React frontend and a monolithic FastAPI backend. The dashboard displays betting opportunities, historical data, and calculated records for NBA, NHL, NCAAB, and NFL.

Key features implemented:
-   **Full NFL Data Backfill:** All 18 weeks of NFL historical data have been scraped, corrected using a user-provided Excel file from , and are displayed in the UI.
-   **NFL Week Selector:** A custom week selector (Weeks 1-18) has replaced the daily calendar for the NFL, allowing users to view games on a weekly basis.
-   **Compound Public Record Modal:** A Breakdown button on the Public Record badge opens a modal that displays a table of betting records grouped by consensus percentage ranges (e.g., 57-58%, 59-60%), sorted from highest to lowest percentage.
-   **Spread Display Fix:** A critical UI bug was fixed where spreads for home favorites were displayed with the wrong sign (e.g., +10.5 instead of -10.5).
-   **Manual Record Updates:** Functionality and scripts are in place to allow for manual updates of all record types (Edge, Betting, Ranks, Public) across all leagues, which has been used multiple times per user requests.
-   **Data-driven UI:** The UI now correctly displays final scores, total lines, public consensus percentages, and HIT/MISS/PUSH results for historical games.

**Last working item**:
-   **Last item agent was working:** The agent was adding a feature to scrape the public betting percentage from  whenever the refresh lines and bet button is clicked. The agent identified the relevant backend endpoint () and the existing consensus scraping function () and was about to integrate the two.
-   **Status:** IN PROGRESS
-   **Agent Testing Done:** N
-   **Which testing method agent to use?** Backend testing agent. The agent should test the  endpoint and verify that the  and  fields are updated in the database for the relevant games.
-   **User Testing Done:** N

**All Pending/In progress Issue list**:
-   **Issue 1:** The  scraper incorrectly identifies bet types (OVER/UNDER) (P1)
-   **Issue 2:** Refactor  monolith (P1)
-   **Issue 3:** The  scraper incorrectly handles Regulation Time bets (P2)

**Issues Detail**:
-   **Issue 1: The  scraper incorrectly identifies bet types (OVER/UNDER)**
    -   **Attempted fixes:** None. This is a long-standing issue.
    -   **Next debug checklist:**
        1.  In , locate the  function.
        2.  Examine the parsing logic that handles bet descriptions like o/u TOTAL...
        3.  Modify the logic (likely with improved regex or string splitting) to correctly determine if the bet is an OVER or UNDER.
    -   **Why fix this issue and what will be achieved with the fix?** To ensure user-placed bets are tracked with the correct direction (Over/Under), which is fundamental to the application's purpose.
    -   **Status:** NOT STARTED
    -   **Is recurring issue?** Y
    -   **Should Test frontend/backend/both after fix?** Backend.
    -   **Blocked on other issue:** None.

-   **Issue 2: Refactor  monolith**
    -   **Attempted fixes:** None.
    -   **Next debug checklist:**
        1.  Create new directories in : , , .
        2.  Start by moving scraping-related functions (e.g., , ) from  into a new file like .
        3.  Update  to import and use the functions from the new module.
    -   **Why fix this issue and what will be achieved with the fix?** To reduce technical debt, improve code organization, and make the backend easier to maintain and extend.
    -   **Status:** NOT STARTED
    -   **Is recurring issue?** Y
    -   **Should Test frontend/backend/both after fix?** Both (regression testing).
    -   **Blocked on other issue:** None.

-   **Issue 3: The  scraper incorrectly handles Regulation Time bets**
    -   **Attempted fixes:** None.
    -   **Next debug checklist:**
        1.  In  within the  function, add logic to detect REG.TIME or similar keywords in the bet description.
        2.  Add a new field to the bet data model (e.g., ) to store this information.
        3.  Update the bet grading logic to correctly handle PUSH outcomes for these bets.
    -   **Why fix this issue and what will be achieved with the fix?** To prevent incorrect bet grading (especially for NHL games) and ensure accurate bet tracking.
    -   **Status:** NOT STARTED
    -   **Is recurring issue?** Y
    -   **Should Test frontend/backend/both after fix?** Backend.
    -   **Blocked on other issue:** None.

**In progress Task List**:
-   **Task 1: Add Public Consensus Scraping to Refresh Lines Button (P0)**
    -   **Where to resume:** In , within the  function, call the existing  function. Then, iterate through the results and update the  fields for the corresponding games in the database.
    -   **What will be achieved with this?** Users will be able to get the latest public betting percentages on demand before a game starts by clicking the refresh button.
    -   **Status:** IN PROGRESS
    -   **Should Test frontend/backend/both after fix?** Backend.
    -   **Blocked on something:** None.

**Upcoming and Future Tasks**
-   **Upcoming Tasks:**
    -   (P2) Begin NCAAB records verification process with user guidance.
-   **Future Tasks:**
    -   (P1) Implement a UI to create and manage custom betting rules.

**Completed work in this session**
-   **NFL Data Overhaul:** Fully backfilled and corrected all 18 weeks of NFL historical data (spreads, scores, total lines) using a user-provided Excel file. Reset all NFL-specific records (Edge, Betting, PPG) to 0-0.
-   **Frontend Feature - Compound Record Modal:** Implemented a modal that displays a breakdown of public betting records by consensus percentage ranges. The sorting was updated to be from highest to lowest percentage.
-   **Frontend Feature - NFL Week Selector:** Replaced the standard calendar with a custom dropdown for selecting NFL games by week (1-18).
-   **UI Bug Fix - Incorrect Spread Display:** Fixed a major bug in  where spreads for home favorites were shown with a positive sign instead of negative.
-   **UI Bug Fix - NFL Historical Columns:** Fixed an issue where the new NFL week view was not showing historical data columns (Score, Public %, Result).
-   **UI/UX Improvement:** Changed the Public Record button to show a Breakdown label instead of the consensus percentage.
-   **Data Correction - NCAAB Edge Calculation:** Fixed a bug where NCAAB edge bets were graded against the PPG average instead of the actual game line, correcting a MISS to a HIT.
-   **Data Correction - Bet Results:** Fixed multiple user-reported bet results, updating their status from PENDING or MISS to MISS or PUSH by correcting the underlying data in the database.
-   **Record Management:** Updated all records for NBA, NHL, and NCAAB based on user-provided totals and set NHL/NCAAB public records to 0-0 as requested.

**Earlier issues found/mentioned but not fixed**
-   **Issue 1:**  OVER/UNDER scraper bug.
-   **Issue 2:**  Regulation Time scraper bug.

**Known issue recurrence from previous fork**
-   **Issue recurrence in previous fork:** The  scraper incorrectly identifies bet types (OVER/UNDER).
-   **Recurrence count:** High.
-   **Status:** NOT STARTED

**Code Architecture**


**Key Technical Concepts**
-   **Web Scraping:** Using Playwright and BeautifulSoup for various sports data sites.
-   **Data Parsing:** Extensive use of  to parse complex, user-provided Excel files, including reading cell formulas to extract data.
-   **Monolithic Backend:** All business logic, API endpoints, database operations, and scraping tasks are located in a single  file.
-   **React Frontend:** A single, large  component manages the state and rendering for the entire dashboard, including complex conditional rendering for different leagues and data states.
-   **Team Name Mapping:** A dictionary was implemented in the frontend as a temporary solution to map NBA team nicknames (e.g., Celtics) to city names (e.g., Boston) to resolve a data inconsistency issue.

**key DB schema**
-   ****: Collection holding historical NFL games. Each document represents a date and contains an array of game objects. Fully updated in this session.
-   **, , **: Collections for other leagues, frequently updated with new lines, scores, and bet results.
-   ****, ****: Collections storing manually adjusted record totals provided by the user.
-   All data resides in the ****.

**changes in tech stack**
-   None.

**All files of reference**
-   : The monolithic backend. All new API endpoints and logic were added here.
-   : The main UI component. Significantly modified to add the NFL week selector, compound record modal, and fix display logic.
-   : The user-provided file used for the final, correct NFL data backfill.

**Areas that need refactoring**:
-   : **CRITICAL.** The file is extremely large and complex, making it difficult to maintain and prone to errors. It urgently needs to be broken down into smaller modules (e.g., , , ).
-   : This component has grown to over 2000 lines. The logic for the new modal, the week selector, and various data display sections should be extracted into their own smaller, reusable components to improve readability and maintainability.

**key api endpoints**
-   ****: Scrapes live lines and bets from . This is the endpoint for the current in-progress task.
-   ****: (New) Fetches the data for the compound public record modal.
-   ****: (New) Fetches NFL games by week number.
-   ****: Modified to return stored 0-0 records for NHL/NCAAB.
-   ****: Modified to include NFL records.
-   ****: Modified to include NFL records.

**Critical Info for New Agent**
-   The user is the source of truth for all data corrections and record totals. Prioritize their requests and trust their provided data.
-   The  file is a monolith and represents significant technical debt. While the user's feature requests often take priority, be prepared to address the pending refactoring task soon. Any modifications to this file should be made with extreme care.
-   The  scraper has long-standing, known bugs related to parsing O/U and Regulation Time bets. These are high-priority fixes in the backlog.
-   Be aware of data inconsistencies, such as the team name mismatch (Boston vs. Celtics), which required a hack in the frontend. Similar issues may exist elsewhere.

**documents and test reports created in this job**
-   None.

**Last 10 User Messages and any pending HUMAN messages**
10. **User:** Asks to scrape public consensus percentage when the refresh lines button is clicked.
9.  **User:** States that a specific bet should be a PUSH, not a MISS.
8.  **User:** Reports a user-placed bet is showing PENDING when it should be a MISS.
7.  **User:** Provides the correct, final record totals for all leagues (NBA, NHL, NCAAB).
6.  **User:** Reports an NCAAB edge bet is incorrectly marked as MISS when it should be a HIT, explaining the calculation logic (compare score to Line, not PPG).
5.  **User:** Reports that three NCAAB games with a valid edge are not being highlighted correctly in the UI.
4.  **User:** Requests that the Public Betting records for NHL and NCAAB be set to 0-0.
3.  **User:** Asks to change the UI of the public record button from showing 57% to a simple Breakdown label.
2.  **User:** Requests that the compound public record table be sorted by consensus percentage (high to low), not by fade win rate.
1.  **User:** Provides a screenshot showing a manual update to the  file and asks the agent to use it to fill in the Line column and set NFL records to 0-0.

**Project Health Check:**
-   **Broken:**
    -   The  scraper's logic for parsing OVER/UNDER bets.
    -   The  scraper's logic for handling Regulation Time bets.
-   **Technical Debt:**
    -   The  monolith is a critical maintenance and stability risk.
    -   The  frontend component is overly large and complex.

**3rd Party Integrations**
-   **Playwright:** For web scraping.
-   **BeautifulSoup:** For parsing HTML content.
-   **APScheduler:** For running scheduled jobs.
-   **openpyxl:** For parsing user-provided Excel files.

**Testing status**
-   **Testing agent used after significant changes:** NO
-   **Troubleshoot agent used after agent stuck in loop:** NO
-   **Test files created:** None
-   **Known regressions:** None

**Credentials to test flow:**
-   **Website:** 
    -   **Betting Account:**  / 
    -   **Lines-only Account:**  / 

**What agent forgot to execute**
-   The critical refactoring of the  monolith was not started.
-   The root cause of the  scraper bugs was not fixed. These high-priority tasks were deferred in favor of the user's active requests for data correction and new UI features.</analysis>
